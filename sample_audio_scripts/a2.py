import sys
import torch
import torchaudio
from transformers import AutoTokenizer, AutoModelForCausalLM

# åŠ è½½ CosyVoice æ¨¡å—
sys.path.append('third_party/Matcha-TTS')
from cosyvoice.cli.cosyvoice import CosyVoice2
from cosyvoice.utils.file_utils import load_wav

# ========== å‚æ•°é…ç½®ï¼ˆæ¥è‡ªé—®å·è¡¨æ ¼ï¼‰ ==========
output_wav = "roleA_happy_01.wav"
text_input = "ä½ çŒœæˆ‘ä»Šå¤©è§åˆ°è°äº†ï¼Ÿæˆ‘å±…ç„¶åœ¨è¡—ä¸Šé‡åˆ°äº†æˆ‘é«˜ä¸­åŒå­¦ï¼"
speaker_id = "0006"
prompt_path = "/scratch/s6029388/CosyVoice/ESD_split/test/0006/Happy/0006_000723.wav"
system_prompt = (
    "å†·å³»å®ˆç¤¼ç³»ï¼šå…‹åˆ¶æ²‰ç¨³ã€ä½éŸ³ç£æ€§ã€ç¤¼è²Œå‘¨å…¨ã€‚å¤–è¡¨å†·é…·ã€ä¸å–„è¨€è¾ï¼Œå´åœ¨å…³é”®æ—¶åˆ»å±•ç°å‡ºç»†è…»ä¸ä½“è´´ã€‚"
)

# ========== åŠ è½½ Yi æ¨¡å‹ ==========
print("ğŸ¤– Loading Yi-1.5-6B-Chat model...")
model_id = "01-ai/Yi-1.5-6B-Chat"
cache_dir = "/scratch/s6029388/huggingface"

tokenizer = AutoTokenizer.from_pretrained(
    model_id,
    trust_remote_code=True,
    cache_dir=cache_dir
)
llm_model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map="auto",
    torch_dtype="auto",
    trust_remote_code=True,
    cache_dir=cache_dir
)

# ========== æ„é€ æ¸…æ´ Prompt ==========
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": f"ä½ æ˜¯ä¸€ä½å†·å³»å®ˆç¤¼çš„ç”·æœ‹å‹ï¼Œç®€çŸ­è‡ªç„¶åœ°å›å¤å¥³ç”Ÿè¿™å¥è¯ã€‚\n\nå¥³ç”Ÿè¯´ï¼š{text_input}"}
]
prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)

inputs = tokenizer(prompt, return_tensors="pt").to(llm_model.device)
outputs = llm_model.generate(
    **inputs,
    max_new_tokens=30,
    do_sample=True,
    top_p=0.95,
    temperature=0.7,
    pad_token_id=tokenizer.eos_token_id
)

reply_raw = tokenizer.decode(outputs[0], skip_special_tokens=True)
reply = reply_raw.split("assistant")[-1].strip()
reply_clean = reply.split("ã€‚")[0] + "ã€‚"

print(f"\nğŸ§¡ æ¨¡å‹ç”Ÿæˆå›å¤ï¼š{reply_clean}")

# ========== åŠ è½½ CosyVoice æ¨¡å‹ ==========
cosyvoice = CosyVoice2(
    'pretrained_models/CosyVoice2-0.5B',
    load_jit=False,
    load_trt=False,
    fp16=False,
    use_flow_cache=False
)

prompt_audio = load_wav(prompt_path, 16000)

# ========== åˆæˆè¯­éŸ³ ==========
print("ğŸ¤ åˆæˆè¯­éŸ³ä¸­...")
for i, j in enumerate(cosyvoice.inference_instruct2(reply_clean, speaker_id, prompt_audio, stream=False)):
    torchaudio.save(output_wav, j['tts_speech'], cosyvoice.sample_rate)
    print(f"âœ… åˆæˆå®Œæˆï¼š{output_wav}")